# "ExecExam: A Tool to Facilitate Effective Executable Examinations in Python"

## Abstract

An executable examinations invites a learner to write, modify, and/or execute
Python source code to solve well-specified programming problems. This type of
assessment enables teachers to determine whether or not a learner can
effectively use a suite of software development tools to implement a program
that meets a specification. After highlighting the challenges associated with
delivering and assessing executable examinations at scale, this presentation
introduces ExecExam, a tool that streamlines and automates the assessment of
Python programming tasks. Leveraging an integration with both local and
cloud-based LLMs, ExecExam provides sophisticated, context-aware feedback for
failing Pytest tests, guiding students towards the effective resolution of
errors while fostering a deeper understanding of Python programming concepts.
Instead of receiving output from a single failed test assertion, students using
ExecExam see a detailed report of all failing checks and specific suggestions
for code fixes or alternative approaches that will enable the student's project
to pass the tests. In addition to overviewing the design and implementation of
ExecExam, this talk will equip teachers with the knowledge needed to deploy
their own executable examinations with the ExecExam tool. More details about the
ExecExam tool is available in its open-source GitHub repository available at
https://github.com/GatorEducator/execexam.

## Key Takeaways

- 

